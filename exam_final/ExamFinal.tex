\documentclass[12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{hyperref}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{hyperref}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[numbers,sort]{natbib}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{footmisc}
\newlength\tindent
\setlength{\tindent}{\parindent}
\setlength{\parindent}{0pt}
\renewcommand{\indent}{\hspace*{\tindent}}


\begin{document} 
    \begin{center}
        \vspace*{1cm}
        
        \textbf{Exam Final}
        
        \vspace{1.5cm}
		IFT6561
        
        \vspace{2.5cm}
        
        \textbf{Gabriel C-Parent}
        
        \vfill

        
        \vspace{0.8cm}

        DIRO\\
        UdeM\\
        \vfill
    \end{center}
\vfill
\newpage



\section*{Part 1}


\subsection*{a}
\textbf{Experimental Results}
\vspace{1 cm}


The algorithm is implemented in San13CMC\textunderscore CV.java.

Beta vector with CV

(0.00628, 0.000347, 0.00138, 0.00501, 0.00458, 0.00271, 0.00276, 0.00703)

Average without CV                         :  0.11448

Average with CV                            :  0.11291

Variance without CV                        : 0.025091

Variance with CV                           : 0.010342

Variance reduction factor                  :   2.4261

\textbf{Confidence interval student 95 without CV  :  0.11448 $\pm$ 0.0031046}

\textbf{Confidence interval student 95 with CV     :  0.11291 $\pm$ 0.0019932}


\vspace{0.5 cm}

As shown in the data, the confidence interval with control variates (CV) is about 1.5 times tighter than without CV. The average of the estimator without CV is also contained within the 95\% student confidence interval of the estimator with CV. Overall, the strategy using CV is pretty good, decreasing the variance by a factor of ~2.4. This was expected, as stated in example 6.26.

\subsection*{b}

%(b) p.101 is pretty much the answer
%le corollaire 6.6 des notes.
The whole concept of stochastic derivatives is explained at p.101 of the book, I'm not rewriting it here, we'll just state the core of the matter.

The first necessary observation is that both $\theta_2$ and $\theta_4$ are parameters for the mean of exponential distributions. Using the same proof as given in example 1.49 of the book, we can explain why our estimator is unbiased.

Suppose we want to estimate $\frac{\delta\mathbbm{E}{[T]}}{\delta \theta_i}$, we can write T as a function of $\theta_i$. 

Say $f$ is the function. $f^{'}(\theta_i, U) = V^{'}_i(\theta_i)$ if the link i is in the longest path and 0 otherwise.
Since, in this case, both $\theta_i$ are the means of exponential random variables, we have $Y_i = Y_i(\theta_i) = -\theta_i ln(1 - U_i)$ and its derivative is $-ln(1-U_i)$. Using the corollary 6.6 to prove that we can interchange the expectation and derivative operators to obtain that our estimator of $f^{'}(\theta_i)$ is unbiased.

Basically, this is the rest of the example 1.49.

\subsection*{c}

As stated in example 1.50 of the book, if the function $f_j(\theta_j, U) = \mathbbm{1}{[T > x]}$, the estimator can only take
two values, 0 and 1. Its derivative is either undefined, when the
function jumps exactly at $\theta_j$ or is 0. It cannot be an unbiased estimator of the derivative because the original function is discontinuous at some point as a function of $\theta_j$.

\subsection*{d}
% estimate
% dP[T>X] / d\theta_i
%CMC example 6.21

The process is explained in \citep{fu_gradient_2006}, beginning of p.17.

First thing, we need to condition on all activities except the ones depending on $\theta_2$ and $\theta_4$. Then we proceed using equation (14) of \citep{fu_sensitivity_2006} for both $\theta_2$ and $\theta_4$.

Further details are given in section 3 of \citep{fu_sensitivity_2006}.

I don't know how to formally prove it, but informally, we need to prove that the derivative of the cumulative functions of the activities (which are exponentials in this particular case) are continuous, unlike the indicator function.

\subsection*{e}
% p.117 for gradient computation code
% http://drum.lib.umd.edu/bitstream/1903/12391/1/Manterola_umd_0117N_12857.pdf
% the term is infinitesimal perturbation analysis (IPA)  + stochastic activity network (SAN) on google for more details

% also SAN_GRADIENT p.15
Sadly, I didn't have enough time to implement the algorithm.


\subsection*{f}

% dP[T <= x] / dx
% derivative of the cdf of the system

%Application of PA to the problem of estimating dP (Y > θ)/dθ also requires SPA, the idea being to
%condition on all activity times except a special (minimal) set that includes at least one activity that must be
%on the optimal (critical) path. Taking any minimal cut set, one can derive an unbiased derivative estimator
%for P (Y > θ) by conditioning on the complement set and then taking the sample path derivative. The details
%are contained in Fu (2005).

This is the same as in \citep{fu_sensitivity_2006}, p. 361. Basically, this is the problem of estimating 
$$\dfrac{\delta P(Y > \theta)}{\delta \theta}$$

We first condition on a set of activity times s.t. the set and its complement have non-zero probability of having an activity on the critical path (that is by obtaining a minimal cut set, as in the class notes).

We then condition on the complement set of activity times and take the sample path derivative \citep{fu_sensitivity_2006}.

The choice of cut set is not trivial.

To give an example of why multiple values of threshold can be calculated at the same time, I refer to the example (i) of p.362 \citep{fu_sensitivity_2006}. Clearly, the value of $\theta$ can be substituted for all the other desired thresholds. This allows us, for each state of the system, to query all the desired values of $\theta$ in parallel without the need of generating more pseudo-random variables.


Sadly, I didn't have enough time to implement the algorithm.

\subsection*{g}
Sadly, I didn't have enough time to implement the algorithm.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PART 2
\section*{2}



\subsection*{a}

The algorithm was implemented in AsianVG\textunderscore RQMC.java.

The point sets (PS) are in corresponding order: Sob + S, Sob + LMS + S, Kor + S, Kor + S + B

PS1 BGSS : 25

PS1 BGBS :  57

PS1 DGBS :  297

PS2 BGSS :  12

PS2 BGBS :  77

PS2 DGBS :  561

PS3 BGSS :  10

PS3 BGBS :  18

PS3 DGBS :  116

PS4 BGSS :  12

PS4 BGBS :  127

PS4 DGBS :  118


The results for Sob+S are lower than expected, especially for the bridge sampling, but the results for Sob + LMS + S match quite well with table 6.12.

For the Korobov lattice, Kor+S matches very well the expected results while Kor+S+B yields much greater variance reduction factor.

I think the cause of this is perhaps an error in the calculation of the variance reduction factor, or otherwise the variation is too important.

The important point is that we reach the same observation that DGBS usually yields superior reduction of variance.




\subsection*{b}
% the answer is in VG pdf and book p.499
% http://wenku.baidu.com/view/4d8ce227ccbff121dd368328.html
% Credit Securitisations and Derivatives: Challenges for the Global Markets p.117

% original pdf
$$
\pi(x) = \dfrac{\lambda^\alpha x^{\alpha -1} \exp{(- \lambda x)}}{\Gamma(\alpha)}
$$

% exponentially twisted pdf definition
$$
\pi_{\theta}(x) = \dfrac{\exp{(\theta x)} \pi(x)}{\mathbbm{M}(\theta)}
$$
where M is the mgf of the Gamma distribution. The exponentially twisted pdf is then

$$
\pi_{\theta}(x) =
\dfrac{\exp(\theta x)}{(1 - \frac{\theta}{\lambda})^{-\alpha}}
\dfrac{\lambda^\alpha x^{\alpha -1} \exp(- \lambda x)}{\Gamma(\alpha)}
$$

this yields the following new densities

$$
\pi_{\theta}(x) = \dfrac{\exp(- (\lambda - \theta)) x^{\alpha - 1}}{\Gamma(\alpha) (\lambda - \theta)^{-\alpha}}
$$

We can generate pseudo-random variable by sampling from the new distributions $Gamma(\alpha, \lambda - \theta)$, since only the scale parameter was changed. 

\vspace{1 cm}
The likelihood ratio to multiply by will be the product of the individual likelihoods:

$$
L(x) = \exp( -\theta x + \alpha(\ln(\frac{\lambda}{\lambda - \theta}))
$$

$$
	L(\omega) = L(x_1) * L(x_2) 
$$

We must simply apply these to the Gamma processes (substituting for the real parameters).



\subsection*{c}

The algorithm was implemented in AsianVG1.java.

Since I couldn't find the relation between $\mathbbm{E}[G^+(1) - G^-(1)]$ and $\theta$, this one isn't working.

What I got is that I know the $\mathbbm{E}[G^+(1) - G^-(1)]$ is equal to the variance gamma $\theta_{VG}$ parameter (by definition). But I can't seem to figure it out going back from the new $\lambda^* = \lambda \pm \theta$ because both terms of the gamma distributions should be related to the original value of $\theta_{VG}$, I mean both the $\mu$ and $\nu$ terms are related to it so I don't see how to do it this way.

Otherwise, I could probably try to use the relation suggested here \url{http://stats.stackexchange.com/questions/48378/difference-of-gamma-random-variables}, but I'm not sure how to proceed.

Since the next many questions depend on it, well, you got me good.

\subsection*{d}

Yeah, hard to compare with c) on that one.

\subsection*{e}

The algorithm was implemented as AsianVGTronquee.java.

As I wasn't able to derive the formula relating the average difference of gamma to the added $\theta$ term, it's pretty hard to compare. However, the code does yield a value similar to the one expected when simulating with BGSS for K=140 and 180, so I guess it isn't so bad.


\subsection*{f}

Sadly, I didn't have enough time to implement the algorithm.


\bibliographystyle{plain}

\bibliography{ExamFinal}

\end{document}


